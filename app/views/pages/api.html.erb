<div class="container mt-3">
  <h2 class="display-4">API Documentation</h2>

  <h3>Streams</h3>
  <p><strong>Streams</strong> are used to group full dumps and subsequent incremental updates and deletes together. Each organization can have many associated streams, but only one <em>default stream</em>. The default stream indicates the current active dump for a given organization, used in other parts of the Aggregator (e.g. harvesting and statistics). You can create new streams from your organization page; only the stream name is required.</p>
  <h3>Uploading a new "full dump"</h3>
  <h4 class="mt-3">API documentation</h4>
  <ul class="list-group">
    <li class="list-group-item">
      <span class="badge bg-info mr-3">POST</span><%= content_tag :span, organization_uploads_url(organization_id: '$ORG_CODE'), class: 'text-monospace font-weight-bolder' %> Upload a file or files to the default stream, or a given stream
      <table class="table">
        <thead><th>Name</th><th>Description</th></thead>
        <tbody>
          <tr><td class="text-monospace">upload[files][]</td><td>Attach one or more files; see the <%= link_to 'data documentation', pages_url(id: 'data') %> for more information about accepted file types. Each uploaded file SHOULD include a <code>Content-Type</code> (one of: <code>application/marc</code>, <code>application/marcxml+xml</code>, or <code>text/plain</code> (for plain text deletes)).</td></tr>
          <tr><td class="text-monospace">upload[url]</td><td>"Upload" from an external URL; POD will attempt to download the file from this URL</td></tr>
          <tr><td class="text-monospace">stream</td><td>(optional) a locally-defined value used to group multiple uploads together</td></tr>
        </tbody>
      </table>
    </li>
    <li class="list-group-item mt-3 border-top">
      <span class="badge bg-info mr-3">POST</span><%= content_tag :span, make_default_organization_streams_url(organization_id: '$ORG_CODE', stream: 'STREAM_ID').sub('STREAM_ID', '$STREAM_ID'), class: 'text-monospace font-weight-bolder' %> Mark a named stream as the default stream
      <table class="table">
        <thead><th>Name</th><th>Description</th></thead>
        <tbody>
          <tr><td class="text-monospace">stream</td><td>a locally-defined value (see above); by making the stream the "default", it will be exposed for harvesting</td></tr>
        </tbody>
      </table>
    </li>
  </ul>

  <h4 class="mt-5">Full example:</h4>
  <pre>
    # Set up some environment information (and, in reality, consider protecting your ACCESS_TOKEN by some means)
    $ export ORG_CODE="..." # put your organization code (e.g. 'stanford')
    $ export ACCESS_TOKEN="..." # put your access token here
    $ export STREAM_ID=$(date +%F) #  or some other identifier for the stream

    # Upload the e.g. MARC21 files in the current directory in a single upload
    $ ls -d * | xargs -I{} printf "\-F 'upload[files][]=@%s;type=application/marc' " {} | xargs curl -H "Authorization: Bearer $ACCESS_TOKEN" --url <%= organization_uploads_url(organization_id: '$ORG_CODE', stream: 'STREAM_ID').sub('STREAM_ID', '$STREAM_ID') %>
    # use application/marcxml+xml for MARCXML, and text/plain for newline-delimited deletes.

    # OR, upload multiple files in parallel
    $ ls -d * | xargs -I{} curl -F 'upload[files][]=@{};type=application/marc' -H 'Authorization: Bearer $ACCESS_TOKEN' --url <%= organization_uploads_url(organization_id: '$ORG_CODE', stream: 'STREAM_ID').sub('STREAM_ID', '$STREAM_ID') %>
    # Make the full dump available for harvesting
    $ curl -X POST -H "Authorization: Bearer $ACCESS_TOKEN" --url <%= make_default_organization_streams_url(organization_id: '$ORG_CODE', stream: 'STREAM_ID').sub('STREAM_ID', '$STREAM_ID') %>
  </pre>

  <h3 id="harvesting">Harvesting full dumps and lists of deleted records</h3>
  <p>The POD Data Lake uses <a href="http://www.openarchives.org/rs/1.1/resourcesync">ResourceSync</a>, an extension of the <a href="https://sitemaps.org/">Sitemaps Protocol</a>, to expose aggregated data in three forms. The links below point to specific ResourceSync resource lists that serve as the starting point for harvesting.</p>
  <p>Like uploads, harvesting data requires an access token. To harvest the data, you would start by harvesting the correct sitemap, and retriving linked resource lists and resources. Currently, the POD Data Lake supports <strong><a href="http://www.openarchives.org/rs/1.1/resourcesync#DestPers">baseline synchronization</a></strong>; incremental synchronization (as defined by the ResourceSync specification) is not yet implemented. Please also note that you must parse and inspect the returned sitemaps to determine the URLs to the original or nomralized ata you wish to harvest.</p>
  <p>Since harvesting using ResourceSync requires parsing the returned sitemaps to find the additional links to follow, using ResourceSync client like <a href="https://github.com/resync/resync"><code>resync</code></a> is recommended.</p>
  <h4 class="mt-3">API documentation</h4>

  <ul class="list-group">
    <li class="list-group-item">
      <span class="badge bg-info mr-3">GET</span><%= content_tag :span, resourcelist_organizations_url, class: 'text-monospace font-weight-bolder' %> Resource list for original uploads (updated in real-time; without normalization)
    </li>
    <li class="list-group-item mt-3 border-top">
      <span class="badge bg-info mr-3">GET</span><%= content_tag :span, normalized_resourcelist_organizations_url(flavor: '$FLAVOR'), class: 'text-monospace font-weight-bolder' %> Resource list for normalized data (either MARC21 or MARCXML)
    </li>
    <li class="list-group-item mt-3 border-top">
      <span class="badge bg-info mr-3">GET</span><%=
      content_tag :span, normalized_resourcelist_organization_stream_url(organization_id: '$ORG_CODE', id: '$STREAM_ID', flavor: '$FLAVOR'),  class: 'text-monospace font-weight-bolder' %> Resource list for specific organization's normalized data in a specific flavor
    </li>
    <li class="list-group-item mt-3 border-top">
      <span class="badge bg-info mr-3">GET</span><%=
      content_tag :span, removed_since_previous_stream_organization_stream_url(organization_id: '$ORG_CODE', id: '$STREAM_ID'),  class: 'text-monospace font-weight-bolder' %> List of record IDs removed since the previous stream was uploaded
    </li>
  </ul>
  <h4 class="mt-5">Full example (using curl)</h4>
  <pre>
    # Set up some environment information (and, in reality, consider protecting your ACCESS_TOKEN by some means)
    $ export ACCESS_TOKEN="..." # put your access token here

    # Get a resource list for normalized data to inspect
    $ curl -H "Authorization: Bearer $ACCESS_TOKEN" --url <%= normalized_resourcelist_organizations_url(flavor: 'marcxml') %>

    # Fetch a specific organization and stream's sitemap for that normalized data, listed in the output above
    $ curl -H "Authorization: Bearer $ACCESS_TOKEN" --url <%=  normalized_resourcelist_organization_stream_url(organization_id: 'brown', id: '2020-11-17b', flavor: 'marcxml') %>

    # Fetch the deletes listed in the output above
    $ curl -H "Authorization: Bearer $ACCESS_TOKEN" --url <%=  removed_since_previous_stream_organization_stream_url(organization_id: 'brown', id: '2020-11-17b') %>
  </pre>
  <h4 class="mt-5">Full example (using resync)</h4>
  <pre>
    # resync requires Python, and the example assumes that Python is already installed.
    # First, install resync:
    $ pip install resync

    # Fetch original, unnormalized uploads into a new directory called "pod"
    $ resync-sync -v --sitemap <%= resourcelist_organizations_url %> --access-token $ACCESS_TOKEN -b https://pod.stanford.edu/ pod

    # Fetch normalized data as MARCXML
    $ resync-sync -v --sitemap <%= normalized_resourcelist_organizations_url(flavor: 'marcxml') %> --access-token $ACCESS_TOKEN -b https://pod.stanford.edu/ pod

    # Fetch normalized data as MARC21 just from Brown University
    $ resync-sync -v --sitemap <%= normalized_resourcelist_organization_stream_url(organization_id: 'brown', id: '2020-11-17b', flavor: 'marc21') %> --access-token $ACCESS_TOKEN -b https://pod.stanford.edu/ pod
  </pre>
</div>
